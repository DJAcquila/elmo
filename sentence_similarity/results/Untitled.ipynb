{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_language</th>\n",
       "      <th>word_embedding</th>\n",
       "      <th>language_model</th>\n",
       "      <th>word_embedding_architecture</th>\n",
       "      <th>word_embedding_size</th>\n",
       "      <th>unk</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>pearson</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>glove</td>\n",
       "      <td>ELMo_wiki</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>glove</td>\n",
       "      <td>ELMo_default</td>\n",
       "      <td>None</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_language word_embedding language_model  \\\n",
       "137             ptbr      wang2vec            None   \n",
       "116             ptbr      word2vec            None   \n",
       "127             ptbr      wang2vec            None   \n",
       "165             ptbr      fasttext            None   \n",
       "47              ptbr      word2vec            None   \n",
       "106             ptbr         glove       ELMo_wiki   \n",
       "91              ptbr      word2vec            None   \n",
       "34              ptbr      word2vec            None   \n",
       "158             ptbr      fasttext            None   \n",
       "70              ptbr         glove    ELMo_default   \n",
       "\n",
       "    word_embedding_architecture word_embedding_size    unk  preprocessed  \\\n",
       "137                        CBOW                 600   True         False   \n",
       "116                        CBOW                 100  False         False   \n",
       "127                        CBOW                1000   True         False   \n",
       "165                        CBOW                 600  False          True   \n",
       "47                         CBOW                 300   True          True   \n",
       "106                        None                  50  False          True   \n",
       "91                    skip-gram                 300   True         False   \n",
       "34                         CBOW                 600  False          True   \n",
       "158                        CBOW                 300   True          True   \n",
       "70                         None                 600  False          True   \n",
       "\n",
       "     pearson    MSE  \n",
       "137    0.440  0.613  \n",
       "116    0.458  0.600  \n",
       "127    0.446  0.609  \n",
       "165    0.367  0.658  \n",
       "47     0.547  0.533  \n",
       "106    0.473  0.591  \n",
       "91     0.484  0.582  \n",
       "34     0.569  0.514  \n",
       "158    0.372  0.656  \n",
       "70     0.497  0.575  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "\n",
    "def generate_dataset():\n",
    "    with open('stats_without_preprocessing.json','r') as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    df['preprocessed'] = False\n",
    "    \n",
    "    with open('stats_with_preprocessing.json','r') as f:\n",
    "        stats = json.load(f)\n",
    "\n",
    "    tmp = pd.DataFrame(stats)\n",
    "    tmp['preprocessed'] = True\n",
    "    df = df.append(tmp)\n",
    "    \n",
    "    with open('stats.json') as f:\n",
    "        bert_stats = json.load(f)\n",
    "    bert_df = pd.DataFrame(bert_stats)\n",
    "    bert_df['preprocessed'] = False\n",
    "    \n",
    "    df = df.append(bert_df)\n",
    "    df = df.reset_index().drop(columns='index')\n",
    "    df['pearson'] = df['pearson'].apply(lambda x: round(float(x), 3))\n",
    "    df['MSE'] = df['MSE'].apply(lambda x: round(float(x), 3))\n",
    "    \n",
    "    relevant_cols = set(df.columns) - set(['MSE', 'pearson', 'timestamp'])\n",
    "    df = df.sort_values(by='timestamp')\n",
    "    df = df.drop_duplicates(subset=relevant_cols, keep='last')\n",
    "    df = df.sort_values(by='pearson', ascending=False)\n",
    "    return df\n",
    "\n",
    "def get_language_model(x):\n",
    "    for item in ['ELMo_wiki', 'ELMo_default', 'ELMo_brwac', 'BERT']:\n",
    "        if item in x:\n",
    "            return item\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_unk(x):\n",
    "    if 'unk' in x:\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "\n",
    "def get_word_embedding(x):\n",
    "    if not 'NILC' in x:\n",
    "        return None\n",
    "    return ' : '.join(x.rstrip('.model').split('/')[-2:len(x)])\n",
    "\n",
    "def get_word_embedding_architecture(x):\n",
    "    if not x:\n",
    "        return None\n",
    "    if 'skip' in x:\n",
    "        return 'skip-gram'\n",
    "    if 'cbow' in x:\n",
    "        return 'CBOW'\n",
    "    return None\n",
    "\n",
    "def get_word_embedding_size(x):\n",
    "    if not x:\n",
    "        return None\n",
    "    return re.findall(r's\\d+.', x)[0].lstrip('s')\n",
    "\n",
    "def isolate_word_embedding_name(x):\n",
    "    if not x:\n",
    "        return None\n",
    "    return x.split(':')[0]\n",
    "\n",
    "def retrieve_results(chosen_language='ptbr'):\n",
    "    df = generate_dataset()\n",
    "    df['language_model'] = df['test'].apply(get_language_model)\n",
    "    df['unk'] = df['test'].apply(get_unk)\n",
    "    df['word_embedding'] = df['test'].apply(get_word_embedding)\n",
    "    df['word_embedding_architecture'] = df['word_embedding'].apply(get_word_embedding_architecture)\n",
    "    df['word_embedding_size'] = df['word_embedding'].apply(get_word_embedding_size)\n",
    "    df['word_embedding'] = df['word_embedding'].apply(isolate_word_embedding_name)\n",
    "    df = df.rename(columns={'lang': 'dataset_language'})\n",
    "    df = df[df['dataset_language'] == chosen_language]\n",
    "    df = df[['dataset_language', \n",
    "             'word_embedding', \n",
    "             'language_model', \n",
    "             'word_embedding_architecture', \n",
    "             'word_embedding_size',\n",
    "            'unk',\n",
    "            'preprocessed',\n",
    "            'pearson',\n",
    "            'MSE']]\n",
    "    df = df.reset_index().drop(columns='index')\n",
    "    df = df.sort_values(by='pearson', ascending=False)\n",
    "    return df\n",
    "\n",
    "retrieve_results(chosen_language='ptbr').sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_results(chosen_language='ptbr').to_csv('propor2020_test_results_ptbr.csv')\n",
    "retrieve_results(chosen_language='pteu').to_csv('propor2020_test_results_pteu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_language_x</th>\n",
       "      <th>word_embedding</th>\n",
       "      <th>language_model</th>\n",
       "      <th>word_embedding_architecture</th>\n",
       "      <th>word_embedding_size</th>\n",
       "      <th>unk</th>\n",
       "      <th>preprocessed_x</th>\n",
       "      <th>pearson_x</th>\n",
       "      <th>MSE_x</th>\n",
       "      <th>dataset_language_y</th>\n",
       "      <th>preprocessed_y</th>\n",
       "      <th>pearson_y</th>\n",
       "      <th>MSE_y</th>\n",
       "      <th>pearson_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.583</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.607</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.537</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>glove</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.575</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.658</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.556</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.601</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.656</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>glove</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.578</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.611</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_language_x word_embedding language_model  \\\n",
       "43               ptbr      wang2vec            None   \n",
       "51               ptbr      wang2vec            None   \n",
       "21               ptbr      wang2vec            None   \n",
       "37               ptbr         glove            None   \n",
       "62               ptbr      fasttext            None   \n",
       "29               ptbr      wang2vec            None   \n",
       "48               ptbr      word2vec            None   \n",
       "60               ptbr      fasttext            None   \n",
       "39               ptbr         glove            None   \n",
       "55               ptbr      wang2vec            None   \n",
       "\n",
       "   word_embedding_architecture word_embedding_size    unk  preprocessed_x  \\\n",
       "43                   skip-gram                  50   True            True   \n",
       "51                        CBOW                1000   True            True   \n",
       "21                        CBOW                 100   True            True   \n",
       "37                        None                1000  False            True   \n",
       "62                        CBOW                 600   True            True   \n",
       "29                   skip-gram                 100   True            True   \n",
       "48                        CBOW                  50   True            True   \n",
       "60                        CBOW                 300   True            True   \n",
       "39                        None                 600   True            True   \n",
       "55                        CBOW                 600   True            True   \n",
       "\n",
       "    pearson_x  MSE_x dataset_language_y  preprocessed_y  pearson_y  MSE_y  \\\n",
       "43      0.483  0.583               ptbr           False      0.436  0.616   \n",
       "51      0.450  0.607               ptbr           False      0.446  0.609   \n",
       "21      0.543  0.537               ptbr           False      0.490  0.578   \n",
       "37      0.495  0.575               ptbr           False      0.396  0.642   \n",
       "62      0.368  0.658               ptbr           False      0.360  0.662   \n",
       "29      0.520  0.556               ptbr           False      0.464  0.596   \n",
       "48      0.458  0.601               ptbr           False      0.429  0.620   \n",
       "60      0.372  0.656               ptbr           False      0.347  0.668   \n",
       "39      0.492  0.578               ptbr           False      0.343  0.671   \n",
       "55      0.443  0.611               ptbr           False      0.440  0.613   \n",
       "\n",
       "    pearson_diff  \n",
       "43         0.047  \n",
       "51         0.004  \n",
       "21         0.053  \n",
       "37         0.099  \n",
       "62         0.008  \n",
       "29         0.056  \n",
       "48         0.029  \n",
       "60         0.025  \n",
       "39         0.149  \n",
       "55         0.003  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_preprocessed_diff(df):\n",
    "    pp_df = df[ df['preprocessed'] == True ]\n",
    "    pp_df = pp_df[pp_df['language_model'].isnull()]\n",
    "    non_pp_df = df[df['preprocessed'] == False ]\n",
    "    non_pp_df = non_pp_df[non_pp_df['language_model'].isnull()]\n",
    "    dataplot = pp_df.merge(non_pp_df, how='inner', on=['word_embedding', 'language_model', 'word_embedding_architecture', 'word_embedding_size', 'unk'])\n",
    "    dataplot['pearson_diff'] = dataplot['pearson_x'] - dataplot['pearson_y']\n",
    "    dataplot = dataplot.sort_values(by='pearson_diff', ascending = False)\n",
    "    return dataplot\n",
    "get_preprocessed_diff(retrieve_results(chosen_language='ptbr')).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preprocessed_diff(retrieve_results(chosen_language='ptbr')).to_csv('diff_preprocessing_ptbr.csv')\n",
    "get_preprocessed_diff(retrieve_results(chosen_language='pteu')).to_csv('diff_preprocessing_pteu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_language_x</th>\n",
       "      <th>word_embedding</th>\n",
       "      <th>language_model</th>\n",
       "      <th>word_embedding_architecture</th>\n",
       "      <th>word_embedding_size</th>\n",
       "      <th>unk_x</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>pearson_x</th>\n",
       "      <th>MSE_x</th>\n",
       "      <th>dataset_language_y</th>\n",
       "      <th>unk_y</th>\n",
       "      <th>pearson_y</th>\n",
       "      <th>MSE_y</th>\n",
       "      <th>pearson_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>pteu</td>\n",
       "      <td>glove</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.980</td>\n",
       "      <td>pteu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1.033</td>\n",
       "      <td>pteu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.354</td>\n",
       "      <td>1.032</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>pteu</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.858</td>\n",
       "      <td>pteu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.858</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.354</td>\n",
       "      <td>1.032</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.924</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.915</td>\n",
       "      <td>-0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.342</td>\n",
       "      <td>1.042</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.915</td>\n",
       "      <td>pteu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>pteu</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.853</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.367</td>\n",
       "      <td>1.021</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>pteu</td>\n",
       "      <td>glove</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.980</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.980</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_language_x word_embedding language_model  \\\n",
       "117               pteu         glove            None   \n",
       "134               pteu      fasttext            None   \n",
       "62                pteu      wang2vec            None   \n",
       "133               pteu      fasttext            None   \n",
       "90                pteu      fasttext            None   \n",
       "137               pteu      fasttext            None   \n",
       "89                pteu      fasttext            None   \n",
       "53                pteu      wang2vec            None   \n",
       "129               pteu      fasttext            None   \n",
       "118               pteu         glove            None   \n",
       "\n",
       "    word_embedding_architecture word_embedding_size  unk_x  preprocessed  \\\n",
       "117                        None                  50  False          True   \n",
       "134                        CBOW                 100  False          True   \n",
       "62                    skip-gram                 300  False          True   \n",
       "133                        CBOW                 100   True          True   \n",
       "90                    skip-gram                  50   True          True   \n",
       "137                        CBOW                  50   True          True   \n",
       "89                    skip-gram                  50  False          True   \n",
       "53                    skip-gram                 600   True          True   \n",
       "129                        CBOW                 300   True          True   \n",
       "118                        None                  50   True          True   \n",
       "\n",
       "     pearson_x  MSE_x dataset_language_y  unk_y  pearson_y  MSE_y  \\\n",
       "117      0.405  0.980               pteu   True      0.404  0.980   \n",
       "134      0.353  1.033               pteu   True      0.354  1.032   \n",
       "62       0.518  0.858               pteu   True      0.519  0.858   \n",
       "133      0.354  1.032               pteu  False      0.353  1.033   \n",
       "90       0.469  0.924               pteu  False      0.477  0.915   \n",
       "137      0.342  1.042               pteu  False      0.341  1.043   \n",
       "89       0.477  0.915               pteu   True      0.469  0.924   \n",
       "53       0.523  0.853               pteu  False      0.522  0.853   \n",
       "129      0.367  1.021               pteu  False      0.366  1.022   \n",
       "118      0.404  0.980               pteu  False      0.405  0.980   \n",
       "\n",
       "     pearson_diff  \n",
       "117         0.001  \n",
       "134        -0.001  \n",
       "62         -0.001  \n",
       "133         0.001  \n",
       "90         -0.008  \n",
       "137         0.001  \n",
       "89          0.008  \n",
       "53          0.001  \n",
       "129         0.001  \n",
       "118        -0.001  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diff_unk(df, status=True):\n",
    "    tmp_df = df[ df['preprocessed'] == status ]\n",
    "    tmp_df = tmp_df[tmp_df['language_model'].isnull()]\n",
    "    dataplot = tmp_df.merge(tmp_df, how='inner', on=['word_embedding', 'language_model', 'word_embedding_architecture', 'word_embedding_size', 'preprocessed'])\n",
    "    dataplot['same'] = dataplot['pearson_x'].combine(dataplot['pearson_y'], lambda x, y: True if x == y else False)\n",
    "    dataplot = dataplot[dataplot['same'] == False]\n",
    "    dataplot = dataplot.drop(columns='same')\n",
    "    dataplot['pearson_diff'] = dataplot['pearson_x'] - dataplot['pearson_y']\n",
    "    dataplot = dataplot.sort_values(by='pearson_diff', ascending=False)\n",
    "    dataplot['pearson_diff'] = dataplot['pearson_diff'].apply(lambda x: round(x, 3))\n",
    "    return dataplot\n",
    "\n",
    "diff_unk(retrieve_results(chosen_language='pteu'), status=True).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_unk(retrieve_results(chosen_language='pteu'), status=True).to_csv('unk_diff_preprocessed_pteu.csv')\n",
    "diff_unk(retrieve_results(chosen_language='ptbr'), status=True).to_csv('unk_diff_preprocessed_ptbr.csv')\n",
    "diff_unk(retrieve_results(chosen_language='pteu'), status=False).to_csv('unk_diff_not_preprocessed_pteu.csv')\n",
    "diff_unk(retrieve_results(chosen_language='ptbr'), status=False).to_csv('unk_diff_not_preprocessed_ptbr.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
