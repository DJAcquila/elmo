{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_language</th>\n",
       "      <th>word_embedding</th>\n",
       "      <th>language_model</th>\n",
       "      <th>word_embedding_architecture</th>\n",
       "      <th>word_embedding_size</th>\n",
       "      <th>unk</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>pearson</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>ELMo_wiki</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>glove</td>\n",
       "      <td>ELMo_wiki</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>glove</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>None</td>\n",
       "      <td>BERT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>glove</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_language word_embedding language_model  \\\n",
       "132             ptbr      wang2vec            None   \n",
       "90              ptbr      word2vec            None   \n",
       "19              ptbr      fasttext       ELMo_wiki   \n",
       "106             ptbr         glove       ELMo_wiki   \n",
       "135             ptbr         glove            None   \n",
       "14              ptbr           None           BERT   \n",
       "181             ptbr      fasttext            None   \n",
       "27              ptbr      word2vec            None   \n",
       "117             ptbr      word2vec            None   \n",
       "188             ptbr         glove            None   \n",
       "\n",
       "    word_embedding_architecture word_embedding_size    unk  preprocessed  \\\n",
       "132                        CBOW                 600   True          True   \n",
       "90                    skip-gram                 100  False          True   \n",
       "19                    skip-gram                 600  False          True   \n",
       "106                        None                  50  False          True   \n",
       "135                        None                 100   True          True   \n",
       "14                         None                None  False         False   \n",
       "181                        CBOW                 300  False         False   \n",
       "27                         CBOW                1000  False          True   \n",
       "117                        CBOW                  50   True          True   \n",
       "188                        None                  50   True         False   \n",
       "\n",
       "     pearson    MSE  \n",
       "132    0.443  0.611  \n",
       "90     0.484  0.583  \n",
       "19     0.592  0.495  \n",
       "106    0.473  0.591  \n",
       "135    0.440  0.613  \n",
       "14     0.604  0.483  \n",
       "181    0.341  0.672  \n",
       "27     0.580  0.505  \n",
       "117    0.458  0.601  \n",
       "188    0.317  0.684  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "\n",
    "def generate_dataset():\n",
    "    with open('stats_without_preprocessing.json','r') as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    df['preprocessed'] = False\n",
    "    \n",
    "    with open('stats_with_preprocessing.json','r') as f:\n",
    "        stats = json.load(f)\n",
    "\n",
    "    tmp = pd.DataFrame(stats)\n",
    "    tmp['preprocessed'] = True\n",
    "    df = df.append(tmp)\n",
    "    \n",
    "    with open('stats.json') as f:\n",
    "        bert_stats = json.load(f)\n",
    "    bert_df = pd.DataFrame(bert_stats)\n",
    "    bert_df['preprocessed'] = False\n",
    "    \n",
    "    df = df.append(bert_df)\n",
    "    df = df.reset_index().drop(columns='index')\n",
    "    df['pearson'] = df['pearson'].apply(lambda x: round(float(x), 3))\n",
    "    df['MSE'] = df['MSE'].apply(lambda x: round(float(x), 3))\n",
    "    \n",
    "    relevant_cols = set(df.columns) - set(['MSE', 'pearson', 'timestamp'])\n",
    "    df = df.sort_values(by='timestamp')\n",
    "    df = df.drop_duplicates(subset=relevant_cols, keep='last')\n",
    "    df = df.sort_values(by='pearson', ascending=False)\n",
    "    return df\n",
    "\n",
    "def get_language_model(x):\n",
    "    for item in ['ELMo_wiki', 'ELMo_default', 'ELMo_brwac', 'BERT']:\n",
    "        if item in x:\n",
    "            return item\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_unk(x):\n",
    "    if 'unk' in x:\n",
    "        return True\n",
    "    else:\n",
    "        return False \n",
    "\n",
    "def get_word_embedding(x):\n",
    "    if not 'NILC' in x:\n",
    "        return None\n",
    "    return ' : '.join(x.rstrip('.model').split('/')[-2:len(x)])\n",
    "\n",
    "def get_word_embedding_architecture(x):\n",
    "    if not x:\n",
    "        return None\n",
    "    if 'skip' in x:\n",
    "        return 'skip-gram'\n",
    "    if 'cbow' in x:\n",
    "        return 'CBOW'\n",
    "    return None\n",
    "\n",
    "def get_word_embedding_size(x):\n",
    "    if not x:\n",
    "        return None\n",
    "    return re.findall(r's\\d+.', x)[0].lstrip('s')\n",
    "\n",
    "def isolate_word_embedding_name(x):\n",
    "    if not x:\n",
    "        return None\n",
    "    return x.split(':')[0]\n",
    "\n",
    "def retrieve_results(chosen_language='ptbr'):\n",
    "    df = generate_dataset()\n",
    "    df['language_model'] = df['test'].apply(get_language_model)\n",
    "    df['unk'] = df['test'].apply(get_unk)\n",
    "    df['word_embedding'] = df['test'].apply(get_word_embedding)\n",
    "    df['word_embedding_architecture'] = df['word_embedding'].apply(get_word_embedding_architecture)\n",
    "    df['word_embedding_size'] = df['word_embedding'].apply(get_word_embedding_size)\n",
    "    df['word_embedding'] = df['word_embedding'].apply(isolate_word_embedding_name)\n",
    "    df = df.rename(columns={'lang': 'dataset_language'})\n",
    "    df = df[df['dataset_language'] == chosen_language]\n",
    "    df = df[['dataset_language', \n",
    "             'word_embedding', \n",
    "             'language_model', \n",
    "             'word_embedding_architecture', \n",
    "             'word_embedding_size',\n",
    "            'unk',\n",
    "            'preprocessed',\n",
    "            'pearson',\n",
    "            'MSE']]\n",
    "    df = df.reset_index().drop(columns='index')\n",
    "    df = df.sort_values(by='pearson', ascending=False)\n",
    "    return df\n",
    "\n",
    "retrieve_results(chosen_language='ptbr').sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_results(chosen_language='ptbr').to_csv('propor2020_test_results_ptbr.csv')\n",
    "retrieve_results(chosen_language='pteu').to_csv('propor2020_test_results_pteu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_language_x</th>\n",
       "      <th>word_embedding</th>\n",
       "      <th>language_model</th>\n",
       "      <th>word_embedding_architecture</th>\n",
       "      <th>word_embedding_size</th>\n",
       "      <th>unk</th>\n",
       "      <th>preprocessed_x</th>\n",
       "      <th>pearson_x</th>\n",
       "      <th>MSE_x</th>\n",
       "      <th>dataset_language_y</th>\n",
       "      <th>preprocessed_y</th>\n",
       "      <th>pearson_y</th>\n",
       "      <th>MSE_y</th>\n",
       "      <th>pearson_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.580</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.658</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.610</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.556</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.520</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.607</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.665</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.607</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.611</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ptbr</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.537</td>\n",
       "      <td>ptbr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_language_x word_embedding language_model  \\\n",
       "40               ptbr      fasttext            None   \n",
       "63               ptbr      fasttext            None   \n",
       "52               ptbr      word2vec            None   \n",
       "30               ptbr      wang2vec            None   \n",
       "12               ptbr      fasttext            None   \n",
       "51               ptbr      wang2vec            None   \n",
       "67               ptbr      fasttext            None   \n",
       "50               ptbr      wang2vec            None   \n",
       "54               ptbr      wang2vec            None   \n",
       "24               ptbr      word2vec            None   \n",
       "\n",
       "   word_embedding_architecture word_embedding_size    unk  preprocessed_x  \\\n",
       "40                   skip-gram                  50   True            True   \n",
       "63                        CBOW                 600  False            True   \n",
       "52                   skip-gram                  50   True            True   \n",
       "30                   skip-gram                 100  False            True   \n",
       "12                   skip-gram                 300   True            True   \n",
       "51                        CBOW                1000   True            True   \n",
       "67                        CBOW                 100  False            True   \n",
       "50                        CBOW                1000  False            True   \n",
       "54                        CBOW                 600  False            True   \n",
       "24                   skip-gram                 600  False            True   \n",
       "\n",
       "    pearson_x  MSE_x dataset_language_y  preprocessed_y  pearson_y  MSE_y  \\\n",
       "40      0.486  0.580               ptbr           False      0.258  0.710   \n",
       "63      0.367  0.658               ptbr           False      0.359  0.662   \n",
       "52      0.444  0.610               ptbr           False      0.409  0.633   \n",
       "30      0.519  0.556               ptbr           False      0.427  0.622   \n",
       "12      0.562  0.520               ptbr           False      0.278  0.703   \n",
       "51      0.450  0.607               ptbr           False      0.446  0.609   \n",
       "67      0.355  0.665               ptbr           False      0.334  0.676   \n",
       "50      0.450  0.607               ptbr           False      0.443  0.611   \n",
       "54      0.443  0.611               ptbr           False      0.438  0.615   \n",
       "24      0.542  0.537               ptbr           False      0.475  0.588   \n",
       "\n",
       "    pearson_diff  \n",
       "40         0.228  \n",
       "63         0.008  \n",
       "52         0.035  \n",
       "30         0.092  \n",
       "12         0.284  \n",
       "51         0.004  \n",
       "67         0.021  \n",
       "50         0.007  \n",
       "54         0.005  \n",
       "24         0.067  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_preprocessed_diff(df):\n",
    "    pp_df = df[ df['preprocessed'] == True ]\n",
    "    pp_df = pp_df[pp_df['language_model'].isnull()]\n",
    "    non_pp_df = df[df['preprocessed'] == False ]\n",
    "    non_pp_df = non_pp_df[non_pp_df['language_model'].isnull()]\n",
    "    dataplot = pp_df.merge(non_pp_df, how='inner', on=['word_embedding', 'language_model', 'word_embedding_architecture', 'word_embedding_size', 'unk'])\n",
    "    dataplot['pearson_diff'] = dataplot['pearson_x'] - dataplot['pearson_y']\n",
    "    dataplot = dataplot.sort_values(by='pearson_diff', ascending = False)\n",
    "    dataplot['pearson_diff'] = dataplot['pearson_diff'].apply(lambda x: round(float(x), 3))\n",
    "    return dataplot\n",
    "get_preprocessed_diff(retrieve_results(chosen_language='ptbr')).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preprocessed_diff(retrieve_results(chosen_language='ptbr')).to_csv('diff_preprocessing_ptbr.csv')\n",
    "get_preprocessed_diff(retrieve_results(chosen_language='pteu')).to_csv('diff_preprocessing_pteu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_language_x</th>\n",
       "      <th>word_embedding</th>\n",
       "      <th>language_model</th>\n",
       "      <th>word_embedding_architecture</th>\n",
       "      <th>word_embedding_size</th>\n",
       "      <th>unk_x</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>pearson_x</th>\n",
       "      <th>MSE_x</th>\n",
       "      <th>dataset_language_y</th>\n",
       "      <th>unk_y</th>\n",
       "      <th>pearson_y</th>\n",
       "      <th>MSE_y</th>\n",
       "      <th>pearson_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.387</td>\n",
       "      <td>1.003</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.389</td>\n",
       "      <td>1.001</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.388</td>\n",
       "      <td>1.002</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.386</td>\n",
       "      <td>1.004</td>\n",
       "      <td>pteu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.387</td>\n",
       "      <td>1.003</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>pteu</td>\n",
       "      <td>glove</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.980</td>\n",
       "      <td>pteu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>CBOW</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1.033</td>\n",
       "      <td>pteu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.354</td>\n",
       "      <td>1.032</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.808</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.796</td>\n",
       "      <td>-0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.847</td>\n",
       "      <td>pteu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>pteu</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.858</td>\n",
       "      <td>pteu</td>\n",
       "      <td>True</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.858</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pteu</td>\n",
       "      <td>fasttext</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.849</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.839</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>pteu</td>\n",
       "      <td>wang2vec</td>\n",
       "      <td>None</td>\n",
       "      <td>skip-gram</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.858</td>\n",
       "      <td>pteu</td>\n",
       "      <td>False</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_language_x word_embedding language_model  \\\n",
       "125               pteu      fasttext            None   \n",
       "121               pteu      fasttext            None   \n",
       "126               pteu      fasttext            None   \n",
       "117               pteu         glove            None   \n",
       "134               pteu      fasttext            None   \n",
       "14                pteu      fasttext            None   \n",
       "45                pteu      fasttext            None   \n",
       "62                pteu      wang2vec            None   \n",
       "34                pteu      fasttext            None   \n",
       "61                pteu      wang2vec            None   \n",
       "\n",
       "    word_embedding_architecture word_embedding_size  unk_x  preprocessed  \\\n",
       "125                        CBOW                1000   True          True   \n",
       "121                        CBOW                 600   True          True   \n",
       "126                        CBOW                1000  False          True   \n",
       "117                        None                  50  False          True   \n",
       "134                        CBOW                 100  False          True   \n",
       "14                    skip-gram                1000   True          True   \n",
       "45                    skip-gram                 600  False          True   \n",
       "62                    skip-gram                 300  False          True   \n",
       "34                    skip-gram                 300   True          True   \n",
       "61                    skip-gram                 300   True          True   \n",
       "\n",
       "     pearson_x  MSE_x dataset_language_y  unk_y  pearson_y  MSE_y  \\\n",
       "125      0.387  1.003               pteu  False      0.386  1.004   \n",
       "121      0.389  1.001               pteu  False      0.388  1.002   \n",
       "126      0.386  1.004               pteu   True      0.387  1.003   \n",
       "117      0.405  0.980               pteu   True      0.404  0.980   \n",
       "134      0.353  1.033               pteu   True      0.354  1.032   \n",
       "14       0.563  0.808               pteu  False      0.571  0.796   \n",
       "45       0.531  0.847               pteu   True      0.525  0.856   \n",
       "62       0.518  0.858               pteu   True      0.519  0.858   \n",
       "34       0.532  0.849               pteu  False      0.539  0.839   \n",
       "61       0.519  0.858               pteu  False      0.518  0.858   \n",
       "\n",
       "     pearson_diff  \n",
       "125         0.001  \n",
       "121         0.001  \n",
       "126        -0.001  \n",
       "117         0.001  \n",
       "134        -0.001  \n",
       "14         -0.008  \n",
       "45          0.006  \n",
       "62         -0.001  \n",
       "34         -0.007  \n",
       "61          0.001  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diff_unk(df, status=True):\n",
    "    tmp_df = df[ df['preprocessed'] == status ]\n",
    "    tmp_df = tmp_df[tmp_df['language_model'].isnull()]\n",
    "    dataplot = tmp_df.merge(tmp_df, how='inner', on=['word_embedding', 'language_model', 'word_embedding_architecture', 'word_embedding_size', 'preprocessed'])\n",
    "    dataplot['same'] = dataplot['pearson_x'].combine(dataplot['pearson_y'], lambda x, y: True if x == y else False)\n",
    "    dataplot = dataplot[dataplot['same'] == False]\n",
    "    dataplot = dataplot.drop(columns='same')\n",
    "    dataplot['pearson_diff'] = dataplot['pearson_x'] - dataplot['pearson_y']\n",
    "    dataplot = dataplot.sort_values(by='pearson_diff', ascending=False)\n",
    "    dataplot['pearson_diff'] = dataplot['pearson_diff'].apply(lambda x: round(float(x), 3))\n",
    "    return dataplot\n",
    "\n",
    "diff_unk(retrieve_results(chosen_language='pteu'), status=True).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_unk(retrieve_results(chosen_language='pteu'), status=True).to_csv('unk_diff_preprocessed_pteu.csv')\n",
    "diff_unk(retrieve_results(chosen_language='ptbr'), status=True).to_csv('unk_diff_preprocessed_ptbr.csv')\n",
    "diff_unk(retrieve_results(chosen_language='pteu'), status=False).to_csv('unk_diff_not_preprocessed_pteu.csv')\n",
    "diff_unk(retrieve_results(chosen_language='ptbr'), status=False).to_csv('unk_diff_not_preprocessed_ptbr.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
